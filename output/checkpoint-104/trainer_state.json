{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 104,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.039603960396039604,
      "grad_norm": 5.921883583068848,
      "learning_rate": 0.0002,
      "loss": 5.1588,
      "step": 1
    },
    {
      "epoch": 0.07920792079207921,
      "grad_norm": 3.7508585453033447,
      "learning_rate": 0.0001980769230769231,
      "loss": 4.5063,
      "step": 2
    },
    {
      "epoch": 0.1188118811881188,
      "grad_norm": 2.139862537384033,
      "learning_rate": 0.00019615384615384615,
      "loss": 4.2075,
      "step": 3
    },
    {
      "epoch": 0.15841584158415842,
      "grad_norm": 1.9513134956359863,
      "learning_rate": 0.00019423076923076924,
      "loss": 4.0985,
      "step": 4
    },
    {
      "epoch": 0.19801980198019803,
      "grad_norm": 1.8497368097305298,
      "learning_rate": 0.00019230769230769233,
      "loss": 4.2677,
      "step": 5
    },
    {
      "epoch": 0.2376237623762376,
      "grad_norm": 1.9614185094833374,
      "learning_rate": 0.00019038461538461538,
      "loss": 4.1616,
      "step": 6
    },
    {
      "epoch": 0.27722772277227725,
      "grad_norm": 2.297595500946045,
      "learning_rate": 0.00018846153846153847,
      "loss": 4.1927,
      "step": 7
    },
    {
      "epoch": 0.31683168316831684,
      "grad_norm": 1.997078776359558,
      "learning_rate": 0.00018653846153846154,
      "loss": 3.8516,
      "step": 8
    },
    {
      "epoch": 0.3564356435643564,
      "grad_norm": 2.4946134090423584,
      "learning_rate": 0.00018461538461538463,
      "loss": 3.7499,
      "step": 9
    },
    {
      "epoch": 0.39603960396039606,
      "grad_norm": 1.8009856939315796,
      "learning_rate": 0.0001826923076923077,
      "loss": 3.7193,
      "step": 10
    },
    {
      "epoch": 0.43564356435643564,
      "grad_norm": 1.8837865591049194,
      "learning_rate": 0.00018076923076923077,
      "loss": 3.8909,
      "step": 11
    },
    {
      "epoch": 0.4752475247524752,
      "grad_norm": 1.865211009979248,
      "learning_rate": 0.00017884615384615386,
      "loss": 3.5851,
      "step": 12
    },
    {
      "epoch": 0.5148514851485149,
      "grad_norm": 1.6764423847198486,
      "learning_rate": 0.00017692307692307693,
      "loss": 3.6364,
      "step": 13
    },
    {
      "epoch": 0.5544554455445545,
      "grad_norm": 2.2986342906951904,
      "learning_rate": 0.000175,
      "loss": 3.7215,
      "step": 14
    },
    {
      "epoch": 0.594059405940594,
      "grad_norm": 2.2517576217651367,
      "learning_rate": 0.0001730769230769231,
      "loss": 3.6021,
      "step": 15
    },
    {
      "epoch": 0.6336633663366337,
      "grad_norm": 2.2303261756896973,
      "learning_rate": 0.00017115384615384616,
      "loss": 3.6778,
      "step": 16
    },
    {
      "epoch": 0.6732673267326733,
      "grad_norm": 3.2512800693511963,
      "learning_rate": 0.00016923076923076923,
      "loss": 3.7293,
      "step": 17
    },
    {
      "epoch": 0.7128712871287128,
      "grad_norm": 2.142596960067749,
      "learning_rate": 0.00016730769230769232,
      "loss": 3.573,
      "step": 18
    },
    {
      "epoch": 0.7524752475247525,
      "grad_norm": 1.9774566888809204,
      "learning_rate": 0.0001653846153846154,
      "loss": 3.6932,
      "step": 19
    },
    {
      "epoch": 0.7920792079207921,
      "grad_norm": 2.0732333660125732,
      "learning_rate": 0.00016346153846153846,
      "loss": 3.2008,
      "step": 20
    },
    {
      "epoch": 0.8316831683168316,
      "grad_norm": 2.458369255065918,
      "learning_rate": 0.00016153846153846155,
      "loss": 3.3864,
      "step": 21
    },
    {
      "epoch": 0.8712871287128713,
      "grad_norm": 2.494508981704712,
      "learning_rate": 0.00015961538461538462,
      "loss": 3.3356,
      "step": 22
    },
    {
      "epoch": 0.9108910891089109,
      "grad_norm": 2.547800302505493,
      "learning_rate": 0.0001576923076923077,
      "loss": 3.2451,
      "step": 23
    },
    {
      "epoch": 0.9504950495049505,
      "grad_norm": 2.687175989151001,
      "learning_rate": 0.00015576923076923078,
      "loss": 3.1944,
      "step": 24
    },
    {
      "epoch": 0.9900990099009901,
      "grad_norm": 2.6338469982147217,
      "learning_rate": 0.00015384615384615385,
      "loss": 3.4837,
      "step": 25
    },
    {
      "epoch": 1.0,
      "grad_norm": 5.649407386779785,
      "learning_rate": 0.00015192307692307692,
      "loss": 3.449,
      "step": 26
    },
    {
      "epoch": 1.0396039603960396,
      "grad_norm": 2.791973114013672,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.9804,
      "step": 27
    },
    {
      "epoch": 1.0792079207920793,
      "grad_norm": 2.573770046234131,
      "learning_rate": 0.00014807692307692308,
      "loss": 2.5921,
      "step": 28
    },
    {
      "epoch": 1.118811881188119,
      "grad_norm": 3.3973069190979004,
      "learning_rate": 0.00014615384615384615,
      "loss": 2.6142,
      "step": 29
    },
    {
      "epoch": 1.1584158415841583,
      "grad_norm": 2.4972267150878906,
      "learning_rate": 0.00014423076923076924,
      "loss": 2.8353,
      "step": 30
    },
    {
      "epoch": 1.198019801980198,
      "grad_norm": 2.598198652267456,
      "learning_rate": 0.0001423076923076923,
      "loss": 2.7066,
      "step": 31
    },
    {
      "epoch": 1.2376237623762376,
      "grad_norm": 3.9276134967803955,
      "learning_rate": 0.00014038461538461538,
      "loss": 3.067,
      "step": 32
    },
    {
      "epoch": 1.2772277227722773,
      "grad_norm": 3.49453067779541,
      "learning_rate": 0.00013846153846153847,
      "loss": 2.5627,
      "step": 33
    },
    {
      "epoch": 1.316831683168317,
      "grad_norm": 3.335672378540039,
      "learning_rate": 0.00013653846153846154,
      "loss": 2.6411,
      "step": 34
    },
    {
      "epoch": 1.3564356435643563,
      "grad_norm": 3.560232162475586,
      "learning_rate": 0.00013461538461538464,
      "loss": 2.5994,
      "step": 35
    },
    {
      "epoch": 1.396039603960396,
      "grad_norm": 3.23966646194458,
      "learning_rate": 0.0001326923076923077,
      "loss": 2.9053,
      "step": 36
    },
    {
      "epoch": 1.4356435643564356,
      "grad_norm": 3.1010329723358154,
      "learning_rate": 0.00013076923076923077,
      "loss": 2.7759,
      "step": 37
    },
    {
      "epoch": 1.4752475247524752,
      "grad_norm": 3.61803936958313,
      "learning_rate": 0.00012884615384615387,
      "loss": 2.6525,
      "step": 38
    },
    {
      "epoch": 1.5148514851485149,
      "grad_norm": 3.151144027709961,
      "learning_rate": 0.00012692307692307693,
      "loss": 3.2839,
      "step": 39
    },
    {
      "epoch": 1.5544554455445545,
      "grad_norm": 3.371396064758301,
      "learning_rate": 0.000125,
      "loss": 2.602,
      "step": 40
    },
    {
      "epoch": 1.5940594059405941,
      "grad_norm": 4.218948841094971,
      "learning_rate": 0.0001230769230769231,
      "loss": 2.0336,
      "step": 41
    },
    {
      "epoch": 1.6336633663366338,
      "grad_norm": 4.1506853103637695,
      "learning_rate": 0.00012115384615384615,
      "loss": 1.9503,
      "step": 42
    },
    {
      "epoch": 1.6732673267326734,
      "grad_norm": 3.8493030071258545,
      "learning_rate": 0.00011923076923076923,
      "loss": 2.2807,
      "step": 43
    },
    {
      "epoch": 1.7128712871287128,
      "grad_norm": 4.577493190765381,
      "learning_rate": 0.00011730769230769231,
      "loss": 1.9215,
      "step": 44
    },
    {
      "epoch": 1.7524752475247525,
      "grad_norm": 5.4466938972473145,
      "learning_rate": 0.00011538461538461538,
      "loss": 2.4182,
      "step": 45
    },
    {
      "epoch": 1.7920792079207921,
      "grad_norm": 4.7643208503723145,
      "learning_rate": 0.00011346153846153846,
      "loss": 2.27,
      "step": 46
    },
    {
      "epoch": 1.8316831683168315,
      "grad_norm": 3.86909556388855,
      "learning_rate": 0.00011153846153846154,
      "loss": 2.5211,
      "step": 47
    },
    {
      "epoch": 1.8712871287128712,
      "grad_norm": 4.956191539764404,
      "learning_rate": 0.00010961538461538463,
      "loss": 2.7283,
      "step": 48
    },
    {
      "epoch": 1.9108910891089108,
      "grad_norm": 4.662747859954834,
      "learning_rate": 0.0001076923076923077,
      "loss": 2.6743,
      "step": 49
    },
    {
      "epoch": 1.9504950495049505,
      "grad_norm": 4.054939270019531,
      "learning_rate": 0.00010576923076923077,
      "loss": 2.5092,
      "step": 50
    },
    {
      "epoch": 1.99009900990099,
      "grad_norm": 4.215396881103516,
      "learning_rate": 0.00010384615384615386,
      "loss": 2.6882,
      "step": 51
    },
    {
      "epoch": 2.0,
      "grad_norm": 11.877211570739746,
      "learning_rate": 0.00010192307692307692,
      "loss": 3.5319,
      "step": 52
    },
    {
      "epoch": 2.0396039603960396,
      "grad_norm": 4.3219194412231445,
      "learning_rate": 0.0001,
      "loss": 2.3542,
      "step": 53
    },
    {
      "epoch": 2.0792079207920793,
      "grad_norm": 5.440512180328369,
      "learning_rate": 9.807692307692307e-05,
      "loss": 1.8257,
      "step": 54
    },
    {
      "epoch": 2.118811881188119,
      "grad_norm": 4.284662246704102,
      "learning_rate": 9.615384615384617e-05,
      "loss": 1.9596,
      "step": 55
    },
    {
      "epoch": 2.1584158415841586,
      "grad_norm": 5.176931381225586,
      "learning_rate": 9.423076923076924e-05,
      "loss": 1.6143,
      "step": 56
    },
    {
      "epoch": 2.198019801980198,
      "grad_norm": 5.0285210609436035,
      "learning_rate": 9.230769230769232e-05,
      "loss": 2.1686,
      "step": 57
    },
    {
      "epoch": 2.237623762376238,
      "grad_norm": 5.5030670166015625,
      "learning_rate": 9.038461538461538e-05,
      "loss": 2.4641,
      "step": 58
    },
    {
      "epoch": 2.2772277227722775,
      "grad_norm": 5.417137622833252,
      "learning_rate": 8.846153846153847e-05,
      "loss": 1.6322,
      "step": 59
    },
    {
      "epoch": 2.3168316831683167,
      "grad_norm": 8.252802848815918,
      "learning_rate": 8.653846153846155e-05,
      "loss": 2.3097,
      "step": 60
    },
    {
      "epoch": 2.3564356435643563,
      "grad_norm": 6.8031415939331055,
      "learning_rate": 8.461538461538461e-05,
      "loss": 1.9393,
      "step": 61
    },
    {
      "epoch": 2.396039603960396,
      "grad_norm": 5.216268539428711,
      "learning_rate": 8.26923076923077e-05,
      "loss": 1.5912,
      "step": 62
    },
    {
      "epoch": 2.4356435643564356,
      "grad_norm": 5.437525272369385,
      "learning_rate": 8.076923076923078e-05,
      "loss": 1.9121,
      "step": 63
    },
    {
      "epoch": 2.4752475247524752,
      "grad_norm": 4.624349117279053,
      "learning_rate": 7.884615384615384e-05,
      "loss": 1.251,
      "step": 64
    },
    {
      "epoch": 2.514851485148515,
      "grad_norm": 4.749549865722656,
      "learning_rate": 7.692307692307693e-05,
      "loss": 1.7875,
      "step": 65
    },
    {
      "epoch": 2.5544554455445545,
      "grad_norm": 6.472519874572754,
      "learning_rate": 7.500000000000001e-05,
      "loss": 2.0808,
      "step": 66
    },
    {
      "epoch": 2.594059405940594,
      "grad_norm": 5.501509189605713,
      "learning_rate": 7.307692307692307e-05,
      "loss": 2.049,
      "step": 67
    },
    {
      "epoch": 2.633663366336634,
      "grad_norm": 5.081812381744385,
      "learning_rate": 7.115384615384616e-05,
      "loss": 1.6791,
      "step": 68
    },
    {
      "epoch": 2.6732673267326734,
      "grad_norm": 4.696557998657227,
      "learning_rate": 6.923076923076924e-05,
      "loss": 0.984,
      "step": 69
    },
    {
      "epoch": 2.7128712871287126,
      "grad_norm": 4.738582134246826,
      "learning_rate": 6.730769230769232e-05,
      "loss": 1.9259,
      "step": 70
    },
    {
      "epoch": 2.7524752475247523,
      "grad_norm": 5.2286553382873535,
      "learning_rate": 6.538461538461539e-05,
      "loss": 1.5827,
      "step": 71
    },
    {
      "epoch": 2.792079207920792,
      "grad_norm": 6.194792747497559,
      "learning_rate": 6.346153846153847e-05,
      "loss": 2.0183,
      "step": 72
    },
    {
      "epoch": 2.8316831683168315,
      "grad_norm": 6.255807876586914,
      "learning_rate": 6.153846153846155e-05,
      "loss": 2.1163,
      "step": 73
    },
    {
      "epoch": 2.871287128712871,
      "grad_norm": 5.61260461807251,
      "learning_rate": 5.9615384615384616e-05,
      "loss": 1.7749,
      "step": 74
    },
    {
      "epoch": 2.910891089108911,
      "grad_norm": 5.472075939178467,
      "learning_rate": 5.769230769230769e-05,
      "loss": 1.7358,
      "step": 75
    },
    {
      "epoch": 2.9504950495049505,
      "grad_norm": 6.4567975997924805,
      "learning_rate": 5.576923076923077e-05,
      "loss": 1.5243,
      "step": 76
    },
    {
      "epoch": 2.99009900990099,
      "grad_norm": 5.090564727783203,
      "learning_rate": 5.384615384615385e-05,
      "loss": 1.6572,
      "step": 77
    },
    {
      "epoch": 3.0,
      "grad_norm": 9.644132614135742,
      "learning_rate": 5.192307692307693e-05,
      "loss": 0.4361,
      "step": 78
    },
    {
      "epoch": 3.0396039603960396,
      "grad_norm": 5.538657188415527,
      "learning_rate": 5e-05,
      "loss": 1.8503,
      "step": 79
    },
    {
      "epoch": 3.0792079207920793,
      "grad_norm": 5.339353561401367,
      "learning_rate": 4.8076923076923084e-05,
      "loss": 1.1407,
      "step": 80
    },
    {
      "epoch": 3.118811881188119,
      "grad_norm": 5.742892742156982,
      "learning_rate": 4.615384615384616e-05,
      "loss": 1.6196,
      "step": 81
    },
    {
      "epoch": 3.1584158415841586,
      "grad_norm": 5.1718950271606445,
      "learning_rate": 4.423076923076923e-05,
      "loss": 2.1667,
      "step": 82
    },
    {
      "epoch": 3.198019801980198,
      "grad_norm": 4.813259601593018,
      "learning_rate": 4.230769230769231e-05,
      "loss": 0.8232,
      "step": 83
    },
    {
      "epoch": 3.237623762376238,
      "grad_norm": 5.2143144607543945,
      "learning_rate": 4.038461538461539e-05,
      "loss": 1.8774,
      "step": 84
    },
    {
      "epoch": 3.2772277227722775,
      "grad_norm": 4.797688961029053,
      "learning_rate": 3.846153846153846e-05,
      "loss": 0.8386,
      "step": 85
    },
    {
      "epoch": 3.3168316831683167,
      "grad_norm": 5.514069557189941,
      "learning_rate": 3.653846153846154e-05,
      "loss": 1.4871,
      "step": 86
    },
    {
      "epoch": 3.3564356435643563,
      "grad_norm": 5.580233097076416,
      "learning_rate": 3.461538461538462e-05,
      "loss": 1.1225,
      "step": 87
    },
    {
      "epoch": 3.396039603960396,
      "grad_norm": 6.528942108154297,
      "learning_rate": 3.269230769230769e-05,
      "loss": 0.83,
      "step": 88
    },
    {
      "epoch": 3.4356435643564356,
      "grad_norm": 4.497555255889893,
      "learning_rate": 3.0769230769230774e-05,
      "loss": 0.6489,
      "step": 89
    },
    {
      "epoch": 3.4752475247524752,
      "grad_norm": 5.103830337524414,
      "learning_rate": 2.8846153846153845e-05,
      "loss": 1.4518,
      "step": 90
    },
    {
      "epoch": 3.514851485148515,
      "grad_norm": 7.28994083404541,
      "learning_rate": 2.6923076923076923e-05,
      "loss": 2.018,
      "step": 91
    },
    {
      "epoch": 3.5544554455445545,
      "grad_norm": 6.014222145080566,
      "learning_rate": 2.5e-05,
      "loss": 1.6618,
      "step": 92
    },
    {
      "epoch": 3.594059405940594,
      "grad_norm": 6.3955302238464355,
      "learning_rate": 2.307692307692308e-05,
      "loss": 1.0809,
      "step": 93
    },
    {
      "epoch": 3.633663366336634,
      "grad_norm": 8.812504768371582,
      "learning_rate": 2.1153846153846154e-05,
      "loss": 1.7027,
      "step": 94
    },
    {
      "epoch": 3.6732673267326734,
      "grad_norm": 6.762465476989746,
      "learning_rate": 1.923076923076923e-05,
      "loss": 1.6009,
      "step": 95
    },
    {
      "epoch": 3.7128712871287126,
      "grad_norm": 5.986609935760498,
      "learning_rate": 1.730769230769231e-05,
      "loss": 1.0819,
      "step": 96
    },
    {
      "epoch": 3.7524752475247523,
      "grad_norm": 5.2088141441345215,
      "learning_rate": 1.5384615384615387e-05,
      "loss": 1.6726,
      "step": 97
    },
    {
      "epoch": 3.792079207920792,
      "grad_norm": 4.483564853668213,
      "learning_rate": 1.3461538461538462e-05,
      "loss": 0.6946,
      "step": 98
    },
    {
      "epoch": 3.8316831683168315,
      "grad_norm": 5.363061904907227,
      "learning_rate": 1.153846153846154e-05,
      "loss": 0.87,
      "step": 99
    },
    {
      "epoch": 3.871287128712871,
      "grad_norm": 5.204215049743652,
      "learning_rate": 9.615384615384616e-06,
      "loss": 1.3287,
      "step": 100
    },
    {
      "epoch": 3.910891089108911,
      "grad_norm": 6.183262348175049,
      "learning_rate": 7.692307692307694e-06,
      "loss": 1.2502,
      "step": 101
    },
    {
      "epoch": 3.9504950495049505,
      "grad_norm": 5.578040599822998,
      "learning_rate": 5.76923076923077e-06,
      "loss": 1.5671,
      "step": 102
    },
    {
      "epoch": 3.99009900990099,
      "grad_norm": 5.906279563903809,
      "learning_rate": 3.846153846153847e-06,
      "loss": 1.401,
      "step": 103
    },
    {
      "epoch": 4.0,
      "grad_norm": 11.395211219787598,
      "learning_rate": 1.9230769230769234e-06,
      "loss": 0.3804,
      "step": 104
    }
  ],
  "logging_steps": 1,
  "max_steps": 104,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 469299953774592.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
